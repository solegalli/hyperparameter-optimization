{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Cross-Validation\n",
    "\n",
    "[Hyperparameter optimization for machine learning - course](https://www.trainindata.com/p/hyperparameter-optimization-for-machine-learning)\n",
    "\n",
    "In this notebook, we will implement nested cross-validation to both select the best hyperparameters and obtain a better estimate of the generalization error of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    GridSearchCV,\n",
    "    train_test_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want more information about the dataset for this demo:\n",
    "\n",
    "# scikit-learn dataset\n",
    "# https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset\n",
    "\n",
    "# dataset information: UCI Machine Learning Repository\n",
    "# https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "    \n",
    "# in short, classification problem, trying to predict whether the tumor\n",
    "# is malignant or benign\n",
    "\n",
    "# load dataset\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "y = y.map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.627417\n",
       "1    0.372583\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cross_val(model, grid):\n",
    "\n",
    "    # configure the outer loop cross-validation procedure\n",
    "    cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # configure the inner loop cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # enumerate splits\n",
    "    outer_results = list()\n",
    "    inner_results = list()\n",
    "\n",
    "    for train_ix, test_ix in cv_outer.split(X_train):\n",
    "\n",
    "        # split data\n",
    "        xtrain, xtest = X_train.loc[train_ix, :], X_train.loc[test_ix, :]\n",
    "        ytrain, ytest = y_train[train_ix], y_train[test_ix]\n",
    "\n",
    "        # define search\n",
    "        search = GridSearchCV(\n",
    "            model, grid, scoring='accuracy', cv=cv_inner, refit=True)\n",
    "\n",
    "        # execute search\n",
    "        search.fit(xtrain, ytrain)\n",
    "\n",
    "        # evaluate model on the hold out dataset\n",
    "        yhat = search.predict(xtest)\n",
    "\n",
    "        # evaluate the model\n",
    "        accuracy = accuracy_score(ytest, yhat)\n",
    "\n",
    "        # store the result\n",
    "        outer_results.append(accuracy)\n",
    "        \n",
    "        inner_results.append(search.best_score_)\n",
    "\n",
    "        # report progress\n",
    "        print(' >> accuracy_outer=%.3f, accuracy_inner=%.3f, cfg=%s' %\n",
    "              (accuracy, search.best_score_, search.best_params_))\n",
    "\n",
    "    # summarize the estimated performance of the model\n",
    "    print()\n",
    "    print('accuracy_outer: %.3f +- %.3f' %\n",
    "          (np.mean(outer_results), np.std(outer_results)))\n",
    "    print('accuracy_inner: %.3f +- %.3f' %\n",
    "          (np.mean(inner_results), np.std(inner_results)))\n",
    "\n",
    "    return search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logit = LogisticRegression(\n",
    "    penalty ='l2', C=1, solver='liblinear', random_state=4, max_iter=10000)\n",
    "\n",
    "# hyperparameter space\n",
    "logit_param = dict(\n",
    "    penalty=['l1', 'l2'],\n",
    "    C=[0.1, 1, 10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> accuracy_outer=0.975, accuracy_inner=0.950, cfg={'C': 10, 'penalty': 'l1'}\n",
      " >> accuracy_outer=0.963, accuracy_inner=0.947, cfg={'C': 10, 'penalty': 'l1'}\n",
      " >> accuracy_outer=0.975, accuracy_inner=0.959, cfg={'C': 10, 'penalty': 'l1'}\n",
      " >> accuracy_outer=0.962, accuracy_inner=0.959, cfg={'C': 10, 'penalty': 'l1'}\n",
      " >> accuracy_outer=0.937, accuracy_inner=0.959, cfg={'C': 10, 'penalty': 'l1'}\n",
      "\n",
      "accuracy_outer: 0.962 +- 0.014\n",
      "accuracy_inner: 0.955 +- 0.005\n"
     ]
    }
   ],
   "source": [
    "logit_search = nested_cross_val(logit, logit_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalization error of the values obtained in the inner loop, is smaller, thus it is optimistically biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9748743718592965\n",
      "Test accuracy:  0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "# let's get the predictions\n",
    "\n",
    "X_train_preds = logit_search.predict(X_train)\n",
    "X_test_preds = logit_search.predict(X_test)\n",
    "\n",
    "# let's examine the accuracy\n",
    "print('Train accuracy: ', accuracy_score(y_train, X_train_preds))\n",
    "print('Test accuracy: ', accuracy_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the accuracy of the model in the train set falls within the interval estimated in the outer loop, but outside the interval estimated with the inner loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param = dict(\n",
    "    n_estimators=[10, 50, 100, 200],\n",
    "    min_samples_split=[0.1, 0.3, 0.5, 1.0],\n",
    "    max_depth=[1,2,3,None],\n",
    "    )\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    min_samples_split=2,\n",
    "    max_depth=3,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> accuracy_outer=0.963, accuracy_inner=0.946, cfg={'max_depth': None, 'min_samples_split': 0.1, 'n_estimators': 200}\n",
      " >> accuracy_outer=0.950, accuracy_inner=0.953, cfg={'max_depth': 2, 'min_samples_split': 0.1, 'n_estimators': 10}\n",
      " >> accuracy_outer=0.938, accuracy_inner=0.956, cfg={'max_depth': None, 'min_samples_split': 0.1, 'n_estimators': 100}\n",
      " >> accuracy_outer=0.987, accuracy_inner=0.934, cfg={'max_depth': 2, 'min_samples_split': 0.1, 'n_estimators': 50}\n",
      " >> accuracy_outer=0.911, accuracy_inner=0.959, cfg={'max_depth': 2, 'min_samples_split': 0.1, 'n_estimators': 200}\n",
      "\n",
      "accuracy_outer: 0.950 +- 0.025\n",
      "accuracy_inner: 0.950 +- 0.009\n"
     ]
    }
   ],
   "source": [
    "rf_search = nested_cross_val(rf, rf_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generalization error of the values obtained in the inner loop, is smaller, thus it is optimistically biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9824120603015075\n",
      "Test accuracy:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# let's get the predictions\n",
    "\n",
    "X_train_preds = rf_search.predict(X_train)\n",
    "X_test_preds = rf_search.predict(X_test)\n",
    "\n",
    "# let's examine the accuracy\n",
    "print('Train accuracy: ', accuracy_score(y_train, X_train_preds))\n",
    "print('Test accuracy: ', accuracy_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
