{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "[Hyperparameter optimization for machine learning - course](https://www.trainindata.com/p/hyperparameter-optimization-for-machine-learning)\n",
    "\n",
    "In this notebook, we will estimate the generalization error of a machine learning model using Cross-Validation schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import comb\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    RepeatedKFold,\n",
    "    LeaveOneOut,\n",
    "    LeavePOut,\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want more information about the dataset for this demo:\n",
    "\n",
    "# scikit-learn dataset\n",
    "# https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset\n",
    "\n",
    "# dataset information: UCI Machine Learning Repository\n",
    "# https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "    \n",
    "# in short, classification problem, trying to predict whether the tumor\n",
    "# is malignant or benign\n",
    "\n",
    "# load dataset\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "y = y.map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.627417\n",
       "1    0.372583\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.925     , 0.95      , 0.9625    , 0.96202532, 0.94936709])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logit = LogisticRegression(\n",
    "    penalty='l2', C=10, solver='liblinear', random_state=4, max_iter=10000)\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "# estimate generalization error\n",
    "clf = cross_validate(\n",
    "    logit,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    cv=kf,  # k-fold\n",
    ")\n",
    "\n",
    "clf['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97169811, 0.96540881, 0.96855346, 0.96238245, 0.97178683])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf['train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train set accuracy:  0.9679659312710711  +-  0.003649325403713798\n",
      "mean test set accuracy:  0.9497784810126582  +-  0.013608919570498668\n"
     ]
    }
   ],
   "source": [
    "print('mean train set accuracy: ', np.mean(\n",
    "    clf['train_score']), ' +- ', np.std(clf['train_score']))\n",
    "print('mean test set accuracy: ', np.mean(\n",
    "    clf['test_score']), ' +- ', np.std(clf['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We expect K * n performance metrics:  50\n",
      "Number of metrics obtained:  50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9       , 0.9375    , 0.975     , 0.96202532, 0.94936709,\n",
       "       0.9625    , 0.9625    , 0.9125    , 0.96202532, 0.92405063,\n",
       "       0.9875    , 0.95      , 0.975     , 0.91139241, 0.96202532,\n",
       "       0.95      , 0.9375    , 0.95      , 0.92405063, 0.96202532,\n",
       "       0.975     , 0.9125    , 0.9375    , 0.94936709, 0.96202532,\n",
       "       0.9875    , 0.9125    , 0.9375    , 0.91139241, 0.96202532,\n",
       "       0.9625    , 0.9375    , 0.95      , 0.92405063, 0.93670886,\n",
       "       0.95      , 0.95      , 0.95      , 0.98734177, 0.88607595,\n",
       "       0.95      , 0.925     , 0.9625    , 0.96202532, 0.94936709,\n",
       "       0.925     , 0.9625    , 0.925     , 0.91139241, 0.96202532])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logit = LogisticRegression(\n",
    "    penalty='l2', C=1, solver='liblinear', random_state=4, max_iter=10000)\n",
    "\n",
    "# Repeated K-Fold Cross-Validation\n",
    "rkf = RepeatedKFold(\n",
    "    n_splits=5,\n",
    "    n_repeats=10,\n",
    "    random_state=4,\n",
    ")\n",
    "\n",
    "print('We expect K * n performance metrics: ', 5*10)\n",
    "\n",
    "# estimate generalization error\n",
    "clf = cross_validate(\n",
    "    logit,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    cv=rkf,  # k-fold\n",
    ")\n",
    "\n",
    "print('Number of metrics obtained: ', len(clf['test_score']))\n",
    "\n",
    "clf['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train set accuracy:  0.9603627688728534  +-  0.006592970819977563\n",
      "mean test set accuracy:  0.9454651898734177  +-  0.023290636388696693\n"
     ]
    }
   ],
   "source": [
    "print('mean train set accuracy: ', np.mean(\n",
    "    clf['train_score']), ' +- ', np.std(clf['train_score']))\n",
    "print('mean test set accuracy: ', np.mean(\n",
    "    clf['test_score']), ' +- ', np.std(clf['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We expect as many metrics as data in the train set:  398\n",
      "Number of metrics obtained:  398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logit = LogisticRegression(\n",
    "    penalty='l2', C=1, solver='liblinear', random_state=4, max_iter=10000)\n",
    "\n",
    "# Leave One Out Cross-Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "print('We expect as many metrics as data in the train set: ', len(X_train))\n",
    "\n",
    "# estimate generalization error\n",
    "clf = cross_validate(\n",
    "    logit,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    cv=loo,  # k-fold\n",
    ")\n",
    "\n",
    "print('Number of metrics obtained: ', len(clf['test_score']))\n",
    "\n",
    "len(clf['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train set accuracy:  0.9575079427363519  +-  0.0012575839695838692\n",
      "mean test set accuracy:  0.9472361809045227  +-  0.22356162123660028\n"
     ]
    }
   ],
   "source": [
    "print('mean train set accuracy: ', np.mean(\n",
    "    clf['train_score']), ' +- ', np.std(clf['train_score']))\n",
    "print('mean test set accuracy: ', np.mean(\n",
    "    clf['test_score']), ' +- ', np.std(clf['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave P Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We expect :  4950.0  metrics\n",
      "Number of metrics obtained:  4950\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logit = LogisticRegression(\n",
    "    penalty='l2', C=1, solver='liblinear', random_state=4, max_iter=10000)\n",
    "\n",
    "# Leave P Out Cross-Validation\n",
    "lpo = LeavePOut(p=2)\n",
    "\n",
    "# I take a smaller sample of the data, otherwise\n",
    "# my computer runs out of memory\n",
    "X_train_small = X_train.head(100)\n",
    "y_train_small = y_train.head(100)\n",
    "\n",
    "# The number of combinations of N things taken k at a time.\n",
    "print('We expect : ', comb(100, 2), ' metrics')\n",
    "\n",
    "\n",
    "# estimate generalization error\n",
    "clf = cross_validate(\n",
    "    logit,\n",
    "    X_train_small,\n",
    "    y_train_small,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    cv=lpo,  # k-fold\n",
    ")\n",
    "\n",
    "print('Number of metrics obtained: ', len(clf['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train set accuracy:  0.9700020614306328  +-  0.0032367717044687024\n",
      "mean test set accuracy:  0.9190909090909091  +-  0.19298082235326716\n"
     ]
    }
   ],
   "source": [
    "print('mean train set accuracy: ', np.mean(\n",
    "    clf['train_score']), ' +- ', np.std(clf['train_score']))\n",
    "print('mean test set accuracy: ', np.mean(\n",
    "    clf['test_score']), ' +- ', np.std(clf['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logit = LogisticRegression(\n",
    "    penalty='l2', C=1, solver='liblinear', random_state=4, max_iter=10000)\n",
    "\n",
    "# Leave P Out Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "# estimate generalization error\n",
    "clf = cross_validate(\n",
    "    logit,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    cv=skf,  # k-fold\n",
    ")\n",
    "\n",
    "len(clf['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean train set accuracy:  0.9623094970525029  +-  0.004457316368446095\n",
      "mean test set accuracy:  0.944620253164557  +-  0.02364900328794808\n"
     ]
    }
   ],
   "source": [
    "print('mean train set accuracy: ', np.mean(\n",
    "    clf['train_score']), ' +- ', np.std(clf['train_score']))\n",
    "print('mean test set accuracy: ', np.mean(\n",
    "    clf['test_score']), ' +- ', np.std(clf['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "234.15px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
