{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search with Hyperopt\n",
    "\n",
    "In this notebook, we will perform **Randomized Search** to select the best **hyperparameters** for a Gradient Boosting Classifier, using the open source Python package [Hyperopt](http://hyperopt.github.io/hyperopt/).\n",
    "\n",
    "The randomized search is performed with the class **rand**.\n",
    "\n",
    "I find the documentation for Hyperopt quite unintuitive, so it helps to refer to the [original article](https://iopscience.iop.org/article/10.1088/1749-4699/8/1/014008/pdf) to understand the different parameters and classes.\n",
    "\n",
    "To step out of Scikit-learn, we will optimise the parameters of a Gradient Boosting Machine of the [xgboost package](https://xgboost.readthedocs.io/en/latest/python/python_intro.html).\n",
    "\n",
    "\n",
    "### Procedure\n",
    "\n",
    "To tune the hyper-parameters of our model we need to:\n",
    "\n",
    "- define a model\n",
    "- define the hyperparameter space\n",
    "- define the objective function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import hp, rand, fmin, Trials\n",
    "\n",
    "# hp: define the hyperparameter space\n",
    "# rand: random search\n",
    "# fmin: optimization function\n",
    "# Trials: to evaluate the different searched hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27  \\\n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target:\n",
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Space\n",
    "\n",
    "- [Hyperopt search space](http://hyperopt.github.io/hyperopt/getting-started/search_spaces/)\n",
    "\n",
    "- [xgb.XGBClassifier hyperparameters](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier)\n",
    "\n",
    "- [xgb general parameters](https://xgboost.readthedocs.io/en/latest/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the hyperparameter space\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 200, 2500, 100),\n",
    "    'max_depth': hp.uniform('max_depth', 1, 10),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.99),\n",
    "    'booster': hp.choice('booster', ['gbtree', 'dart']),\n",
    "    'gamma': hp.quniform('gamma', 0.01, 10, 0.1),\n",
    "    'subsample': hp.uniform('subsample', 0.50, 0.90),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.50, 0.99),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.50, 0.99),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.50, 0.99),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 1, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the objective function\n",
    "\n",
    "This is the hyperparameter response space, the function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the objective function takes the hyperparameter space\n",
    "# as input\n",
    "\n",
    "def objective(params):\n",
    "\n",
    "    # we need a dictionary to indicate which value from the space\n",
    "    # to attribute to each value of the hyperparameter in the xgb\n",
    "    params_dict = {\n",
    "        'n_estimators': int(params['n_estimators']), # important int, as it takes integers only\n",
    "        'max_depth': int(params['max_depth']), # important int, as it takes integers only\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'booster': params['booster'],\n",
    "        'gamma': params['gamma'],\n",
    "        'subsample': params['subsample'],\n",
    "        'colsample_bytree': params['colsample_bytree'],\n",
    "        'colsample_bylevel': params['colsample_bylevel'],\n",
    "        'colsample_bynode': params['colsample_bynode'],\n",
    "        'random_state': 1000,\n",
    "    }\n",
    "\n",
    "    # with ** we pass the items in the dictionary as parameters\n",
    "    # to the xgb\n",
    "    gbm = xgb.XGBClassifier(**params_dict)\n",
    "\n",
    "    # train with cv\n",
    "    score = cross_val_score(gbm, X_train, y_train,\n",
    "                            scoring='accuracy', cv=5, n_jobs=4).mean()\n",
    "\n",
    "    # to minimize, we negate the score\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "\n",
    "[fmin](http://hyperopt.github.io/hyperopt/getting-started/minimizing_functions/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 50/50 [04:37<00:00,  5.55s/trial, best loss: -0.9723734177215191]\n"
     ]
    }
   ],
   "source": [
    "# fmin performs the minimization\n",
    "# rand.suggest samples the parameters at random\n",
    "# i.e., performs the random search\n",
    "\n",
    "search = fmin(\n",
    "    fn=objective,\n",
    "    space=param_grid,\n",
    "    max_evals=50,\n",
    "    rstate=np.random.RandomState(42),\n",
    "    algo=rand.suggest,  # randomized search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmin returns a dictionary with the best parameters\n",
    "\n",
    "type(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 1,\n",
       " 'colsample_bylevel': 0.5217427505726557,\n",
       " 'colsample_bynode': 0.7838349250815994,\n",
       " 'colsample_bytree': 0.8330171536893886,\n",
       " 'gamma': 0.7000000000000001,\n",
       " 'learning_rate': 0.33912550667486263,\n",
       " 'max_depth': 2.2743235265423642,\n",
       " 'n_estimators': 1100.0,\n",
       " 'reg_lambda': 18.144260767558816,\n",
       " 'subsample': 0.5867182562146751}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another dictionary to pass the search items as parameters\n",
    "# to a new xgb\n",
    "\n",
    "best_hp_dict = {\n",
    "        'n_estimators': int(search['n_estimators']), # important int, as it takes integers only\n",
    "        'max_depth': int(search['max_depth']), # important int, as it takes integers only\n",
    "        'learning_rate': search['learning_rate'],\n",
    "        'booster': 'gbtree',\n",
    "        'gamma': search['gamma'],\n",
    "        'subsample': search['subsample'],\n",
    "        'colsample_bytree': search['colsample_bytree'],\n",
    "        'colsample_bylevel': search['colsample_bylevel'],\n",
    "        'colsample_bynode': search['colsample_bynode'],\n",
    "        'random_state': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sole\\documents\\repositories\\envs\\html\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=0.5217427505726557,\n",
       "              colsample_bynode=0.7838349250815994,\n",
       "              colsample_bytree=0.8330171536893886, gamma=0.7000000000000001,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.33912550667486263, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=1100, n_jobs=4, num_parallel_tree=1,\n",
       "              random_state=1000, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=0.5867182562146751, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after the search we can train the model with the\n",
    "# best parameters manually\n",
    "\n",
    "gbm_final = xgb.XGBClassifier(**best_hp_dict)\n",
    "\n",
    "gbm_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc:  1.0\n",
      "Test roc_auc:  0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "X_train_preds = gbm_final.predict(X_train)\n",
    "X_test_preds = gbm_final.predict(X_test)\n",
    "\n",
    "print('Train accuracy: ', accuracy_score(y_train, X_train_preds))\n",
    "print('Test accuracy: ', accuracy_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the search\n",
    "\n",
    "We can use Trials if we want to look into the search, and the performance values encountered during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 50/50 [05:25<00:00,  6.52s/trial, best loss: -0.9723734177215191]\n"
     ]
    }
   ],
   "source": [
    "second_search = fmin(\n",
    "    fn=objective,\n",
    "    space=param_grid,\n",
    "    max_evals=50,\n",
    "    rstate=np.random.RandomState(42),\n",
    "    algo=rand.suggest,  # randomized search\n",
    "    trials = trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 1,\n",
       " 'colsample_bylevel': 0.5217427505726557,\n",
       " 'colsample_bynode': 0.7838349250815994,\n",
       " 'colsample_bytree': 0.8330171536893886,\n",
       " 'gamma': 0.7000000000000001,\n",
       " 'learning_rate': 0.33912550667486263,\n",
       " 'max_depth': 2.2743235265423642,\n",
       " 'n_estimators': 1100.0,\n",
       " 'reg_lambda': 18.144260767558816,\n",
       " 'subsample': 0.5867182562146751}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best hyperparameters\n",
    "\n",
    "second_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 1,\n",
       " 'colsample_bylevel': 0.5217427505726557,\n",
       " 'colsample_bynode': 0.7838349250815994,\n",
       " 'colsample_bytree': 0.8330171536893886,\n",
       " 'gamma': 0.7000000000000001,\n",
       " 'learning_rate': 0.33912550667486263,\n",
       " 'max_depth': 2.2743235265423642,\n",
       " 'n_estimators': 1100.0,\n",
       " 'reg_lambda': 18.144260767558816,\n",
       " 'subsample': 0.5867182562146751}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the best hyperparameters can also be found in\n",
    "# trials\n",
    "\n",
    "trials.argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bynode</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.586348</td>\n",
       "      <td>0.581706</td>\n",
       "      <td>0.604089</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.485483</td>\n",
       "      <td>3.875025</td>\n",
       "      <td>400.0</td>\n",
       "      <td>16.820009</td>\n",
       "      <td>0.681880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.649187</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>0.671956</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.666745</td>\n",
       "      <td>3.842196</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>14.826789</td>\n",
       "      <td>0.664042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.811507</td>\n",
       "      <td>0.673258</td>\n",
       "      <td>0.567771</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.856845</td>\n",
       "      <td>9.561015</td>\n",
       "      <td>900.0</td>\n",
       "      <td>17.782990</td>\n",
       "      <td>0.834955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.773097</td>\n",
       "      <td>0.868261</td>\n",
       "      <td>0.576170</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.194196</td>\n",
       "      <td>4.899995</td>\n",
       "      <td>400.0</td>\n",
       "      <td>18.455728</td>\n",
       "      <td>0.677933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.946845</td>\n",
       "      <td>0.927589</td>\n",
       "      <td>0.870342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522591</td>\n",
       "      <td>8.224883</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>4.265560</td>\n",
       "      <td>0.824958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  colsample_bylevel  colsample_bynode  colsample_bytree  gamma  \\\n",
       "0        0           0.586348          0.581706          0.604089    3.0   \n",
       "1        1           0.649187          0.862357          0.671956    4.1   \n",
       "2        0           0.811507          0.673258          0.567771    0.6   \n",
       "3        0           0.773097          0.868261          0.576170    4.5   \n",
       "4        1           0.946845          0.927589          0.870342    1.0   \n",
       "\n",
       "   learning_rate  max_depth  n_estimators  reg_lambda  subsample  \n",
       "0       0.485483   3.875025         400.0   16.820009   0.681880  \n",
       "1       0.666745   3.842196        2300.0   14.826789   0.664042  \n",
       "2       0.856845   9.561015         900.0   17.782990   0.834955  \n",
       "3       0.194196   4.899995         400.0   18.455728   0.677933  \n",
       "4       0.522591   8.224883        1600.0    4.265560   0.824958  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the search hyperparameter combinations\n",
    "\n",
    "pd.DataFrame(trials.vals).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.954842</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.959778</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.947278</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.944684</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.937215</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss status\n",
       "0 -0.954842     ok\n",
       "1 -0.959778     ok\n",
       "2 -0.947278     ok\n",
       "3 -0.944684     ok\n",
       "4 -0.937215     ok"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the results\n",
    "\n",
    "pd.DataFrame(trials.results).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booster</th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bynode</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample</th>\n",
       "      <th>loss</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.510049</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.817319</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.822129</td>\n",
       "      <td>7.697500</td>\n",
       "      <td>500.0</td>\n",
       "      <td>13.191226</td>\n",
       "      <td>0.871029</td>\n",
       "      <td>-0.927120</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.802435</td>\n",
       "      <td>0.768359</td>\n",
       "      <td>0.713257</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.844447</td>\n",
       "      <td>3.557713</td>\n",
       "      <td>400.0</td>\n",
       "      <td>12.464280</td>\n",
       "      <td>0.630523</td>\n",
       "      <td>-0.931994</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.843887</td>\n",
       "      <td>0.671379</td>\n",
       "      <td>0.735708</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.371848</td>\n",
       "      <td>7.654980</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>5.878559</td>\n",
       "      <td>0.718547</td>\n",
       "      <td>-0.932215</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.963230</td>\n",
       "      <td>0.801626</td>\n",
       "      <td>0.734169</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.967741</td>\n",
       "      <td>4.810020</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>6.787636</td>\n",
       "      <td>0.632172</td>\n",
       "      <td>-0.937152</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.946845</td>\n",
       "      <td>0.927589</td>\n",
       "      <td>0.870342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522591</td>\n",
       "      <td>8.224883</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>4.265560</td>\n",
       "      <td>0.824958</td>\n",
       "      <td>-0.937215</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   booster  colsample_bylevel  colsample_bynode  colsample_bytree  gamma  \\\n",
       "0        0           0.510049          0.824438          0.817319    5.3   \n",
       "1        0           0.802435          0.768359          0.713257    3.0   \n",
       "2        1           0.843887          0.671379          0.735708    8.5   \n",
       "3        0           0.963230          0.801626          0.734169    3.7   \n",
       "4        1           0.946845          0.927589          0.870342    1.0   \n",
       "\n",
       "   learning_rate  max_depth  n_estimators  reg_lambda  subsample      loss  \\\n",
       "0       0.822129   7.697500         500.0   13.191226   0.871029 -0.927120   \n",
       "1       0.844447   3.557713         400.0   12.464280   0.630523 -0.931994   \n",
       "2       0.371848   7.654980        1400.0    5.878559   0.718547 -0.932215   \n",
       "3       0.967741   4.810020        2200.0    6.787636   0.632172 -0.937152   \n",
       "4       0.522591   8.224883        1600.0    4.265560   0.824958 -0.937215   \n",
       "\n",
       "  status  \n",
       "0     ok  \n",
       "1     ok  \n",
       "2     ok  \n",
       "3     ok  \n",
       "4     ok  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat([\n",
    "    pd.DataFrame(trials.vals),\n",
    "    pd.DataFrame(trials.results)],\n",
    "    axis=1,\n",
    ").sort_values(by='loss', ascending=False).reset_index(drop=True)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Hyperparam combination')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results['loss'].plot()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Hyperparam combination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9723734177215191"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(trials.results)['loss'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "html",
   "language": "python",
   "name": "html"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
