{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search algorithms within Hyperopt\n",
    "\n",
    "[Hyperopt](http://hyperopt.github.io/hyperopt/) provides 3 search algorithms:\n",
    "\n",
    "- Randomized search\n",
    "- Annealing\n",
    "- Tree-structured Parzen Estimators\n",
    "\n",
    "\n",
    "I find the documentation for Hyperopt quite unintuitive, so it helps to refer to the [original article](https://iopscience.iop.org/article/10.1088/1749-4699/8/1/014008/pdf) to understand the different parameters and classes.\n",
    "\n",
    "### Procedure\n",
    "\n",
    "To tune the hyper-parameters of our model we need to:\n",
    "\n",
    "- define a model\n",
    "- define the hyperparameter space\n",
    "- define the objective function we want to minimize.\n",
    "- Run the minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp: define the hyperparameter space\n",
    "# fmin: optimization function\n",
    "# Trials: to evaluate the different searched hyperparameters\n",
    "from hyperopt import hp, fmin\n",
    "\n",
    "# the search algorithms\n",
    "from hyperopt import rand, anneal, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "y = y.map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.627417\n",
       "1    0.372583\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target:\n",
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Space\n",
    "\n",
    "- [Hyperopt search space](http://hyperopt.github.io/hyperopt/getting-started/search_spaces/)\n",
    "\n",
    "- [xgb.XGBClassifier hyperparameters](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier)\n",
    "\n",
    "- [xgb general parameters](https://xgboost.readthedocs.io/en/latest/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the hyperparameter space\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 200, 2500, 100),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 10, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.001), np.log(1)),\n",
    "    'booster': hp.choice('booster', ['gbtree', 'dart']),\n",
    "    'gamma': hp.loguniform('gamma', np.log(0.01), np.log(10)),\n",
    "    'subsample': hp.uniform('subsample', 0.50, 0.90),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.50, 0.99),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.50, 0.99),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.50, 0.99),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 1, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the objective function\n",
    "\n",
    "This is the hyperparameter response space, the function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the objective function takes the hyperparameter space\n",
    "# as input\n",
    "\n",
    "def objective(params):\n",
    "\n",
    "    # we need a dictionary to indicate which value from the space\n",
    "    # to attribute to each value of the hyperparameter in the xgb\n",
    "    params_dict = {\n",
    "        # important int, as it takes integers only\n",
    "        'n_estimators': int(params['n_estimators']),\n",
    "        # important int, as it takes integers only\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'booster': params['booster'],\n",
    "        'gamma': params['gamma'],\n",
    "        'subsample': params['subsample'],\n",
    "        'colsample_bytree': params['colsample_bytree'],\n",
    "        'colsample_bylevel': params['colsample_bylevel'],\n",
    "        'colsample_bynode': params['colsample_bynode'],\n",
    "        'random_state': 1000,\n",
    "    }\n",
    "\n",
    "    # with ** we pass the items in the dictionary as parameters\n",
    "    # to the xgb\n",
    "    gbm = xgb.XGBClassifier(**params_dict)\n",
    "\n",
    "    # train with cv\n",
    "    score = cross_val_score(gbm, X_train, y_train,\n",
    "                            scoring='accuracy', cv=3, n_jobs=4).mean()\n",
    "\n",
    "    # to minimize, we negate the score\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search\n",
    "\n",
    "[fmin](http://hyperopt.github.io/hyperopt/getting-started/minimizing_functions/): returns the best hyperparameters found during the search.\n",
    "\n",
    "**rand** performs randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [3:44:38<00:00, 269.58s/trial, best loss: -0.9673425989215462]\n"
     ]
    }
   ],
   "source": [
    "# fmin performs the minimization\n",
    "# rand.suggest samples the parameters at random\n",
    "# i.e., performs the random search\n",
    "\n",
    "random_search = fmin(\n",
    "    fn=objective,\n",
    "    space=param_grid,\n",
    "    max_evals=50,\n",
    "    rstate=np.random.default_rng(42),\n",
    "    algo=rand.suggest,  # randomized search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmin returns a dictionary with the best parameters\n",
    "\n",
    "type(random_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 0,\n",
       " 'colsample_bylevel': 0.5161576208947579,\n",
       " 'colsample_bynode': 0.9019214112877341,\n",
       " 'colsample_bytree': 0.7115499953437103,\n",
       " 'gamma': 0.09289745331036332,\n",
       " 'learning_rate': 0.4943505207810376,\n",
       " 'max_depth': 1.0,\n",
       " 'n_estimators': 1200.0,\n",
       " 'reg_lambda': 16.437671869767993,\n",
       " 'subsample': 0.8527909973191448}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another dictionary to pass the search items as parameters\n",
    "# to a new xgb\n",
    "\n",
    "def create_param_grid(search, booster):\n",
    "    best_hp_dict = {\n",
    "            'n_estimators': int(search['n_estimators']), # important int, as it takes integers only\n",
    "            'max_depth': int(search['max_depth']), # important int, as it takes integers only\n",
    "            'learning_rate': search['learning_rate'],\n",
    "            'booster': booster,\n",
    "            'gamma': search['gamma'],\n",
    "            'subsample': search['subsample'],\n",
    "            'colsample_bytree': search['colsample_bytree'],\n",
    "            'colsample_bylevel': search['colsample_bylevel'],\n",
    "            'colsample_bynode': search['colsample_bynode'],\n",
    "            'random_state': 1000,\n",
    "    }\n",
    "    return best_hp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train roc_auc:  1.0\n",
      "Test roc_auc:  0.9970605526161082\n"
     ]
    }
   ],
   "source": [
    "# after the search we can train the model with the\n",
    "# best parameters manually\n",
    "\n",
    "best_params = create_param_grid(random_search, 'gbtree')\n",
    "\n",
    "gbm_rand = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "gbm_rand.fit(X_train, y_train)\n",
    "\n",
    "X_train_preds = gbm_rand.predict_proba(X_train)[:,1]\n",
    "X_test_preds = gbm_rand.predict_proba(X_test)[:,1]\n",
    "\n",
    "print()\n",
    "print('Train roc_auc: ', roc_auc_score(y_train, X_train_preds))\n",
    "print('Test roc_auc: ', roc_auc_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annealing\n",
    "\n",
    "**anneal**: performs annealing method as search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [7:29:42<00:00, 539.66s/trial, best loss: -0.9724120908331434]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'booster': 1,\n",
       " 'colsample_bylevel': 0.6426514831348433,\n",
       " 'colsample_bynode': 0.661482327789029,\n",
       " 'colsample_bytree': 0.8032977885169955,\n",
       " 'gamma': 1.1968402397736302,\n",
       " 'learning_rate': 0.1443996470732946,\n",
       " 'max_depth': 5.0,\n",
       " 'n_estimators': 1700.0,\n",
       " 'reg_lambda': 19.262067305376334,\n",
       " 'subsample': 0.7356258356204477}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmin performs the minimization\n",
    "# anneal.suggest samples the parameters\n",
    "\n",
    "anneal_search = fmin(\n",
    "    fn=objective,\n",
    "    space=param_grid,\n",
    "    max_evals=50,\n",
    "    rstate=np.random.default_rng(42),\n",
    "    algo=anneal.suggest,  # annealing search\n",
    ")\n",
    "\n",
    "anneal_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train roc_auc:  1.0\n",
      "Test roc_auc:  0.9982363315696648\n"
     ]
    }
   ],
   "source": [
    "# after the search we can train the model with the\n",
    "# best parameters manually\n",
    "\n",
    "best_params = create_param_grid(anneal_search, 'gbtree')\n",
    "\n",
    "gbm_anneal = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "gbm_anneal.fit(X_train, y_train)\n",
    "\n",
    "X_train_preds = gbm_anneal.predict_proba(X_train)[:,1]\n",
    "X_test_preds = gbm_anneal.predict_proba(X_test)[:,1]\n",
    "\n",
    "print()\n",
    "print('Train roc_auc: ', roc_auc_score(y_train, X_train_preds))\n",
    "print('Test roc_auc: ', roc_auc_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPE\n",
    "\n",
    "**tpe**: performs TPE search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [3:22:24<00:00, 242.88s/trial, best loss: -0.9648553201184781]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'booster': 1,\n",
       " 'colsample_bylevel': 0.7603290861002258,\n",
       " 'colsample_bynode': 0.6497985715113674,\n",
       " 'colsample_bytree': 0.5577945635716377,\n",
       " 'gamma': 0.23791313590730973,\n",
       " 'learning_rate': 0.3131052896625003,\n",
       " 'max_depth': 4.0,\n",
       " 'n_estimators': 1500.0,\n",
       " 'reg_lambda': 18.50816753530551,\n",
       " 'subsample': 0.5011284761202427}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmin performs the minimization\n",
    "# tpe.suggest samples the parameters\n",
    "\n",
    "tpe_search = fmin(\n",
    "    fn=objective,\n",
    "    space=param_grid,\n",
    "    max_evals=50,\n",
    "    rstate=np.random.default_rng(42),\n",
    "    algo=tpe.suggest,  # tpe\n",
    ")\n",
    "\n",
    "tpe_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train roc_auc:  1.0\n",
      "Test roc_auc:  0.9960317460317459\n"
     ]
    }
   ],
   "source": [
    "# after the search we can train the model with the\n",
    "# best parameters manually\n",
    "\n",
    "best_hp_dict = create_param_grid(tpe_search, 'gbtree')\n",
    "\n",
    "gbm_final = xgb.XGBClassifier(**best_hp_dict)\n",
    "\n",
    "gbm_final.fit(X_train, y_train)\n",
    "\n",
    "X_train_preds = gbm_final.predict_proba(X_train)[:,1]\n",
    "X_test_preds = gbm_final.predict_proba(X_test)[:,1]\n",
    "\n",
    "print()\n",
    "print('Train roc_auc: ', roc_auc_score(y_train, X_train_preds))\n",
    "print('Test roc_auc: ', roc_auc_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
