{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Search Spaces with Hyperopt\n",
    "\n",
    "In this notebooks, we will create a conditional (or nested) hyperparameter space to optimize the hyperparameters of 3 different off-the-shelf algorithms.\n",
    "\n",
    "Utilizing the breast cancer dataset, we will optimize the hyperparameters for a linear regression, a random forest and a gradient boosting machine within the same search.\n",
    "\n",
    "By the end of the search, we will know:\n",
    "\n",
    "- which algorithm returns the best results\n",
    "- which are the best hyperparameters for said algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp: define the hyperparameter space\n",
    "# fmin: optimization function\n",
    "# Trials: to evaluate the different searched hyperparameters\n",
    "from hyperopt import hp, fmin, Trials\n",
    "\n",
    "# the search algorithms\n",
    "from hyperopt import anneal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "y = y.map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.627417\n",
       "1    0.372583\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target:\n",
    "# percentage of benign (0) and malign tumors (1)\n",
    "\n",
    "y.value_counts() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Hyperparameter Space\n",
    "\n",
    "- [Hyperopt search space](http://hyperopt.github.io/hyperopt/getting-started/search_spaces/)\n",
    "\n",
    "We need to define 3 spaces, 1 for each algorithm, nested or conditional to the algorithm. We create all this spaces in a master configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# determine the hyperparameter space\n",
    "# ==================================\n",
    "\n",
    "# we create dictionaries with 2 keys: \"model\" and \"params\"\n",
    "# in \"model\" we specify the algorithm, in \"params\", we pass\n",
    "# a dictionary with the space for that particular algorithm\n",
    "\n",
    "# important: pass the model as class and not\n",
    "# instantiated, thus LogisticRegression istead of\n",
    "# LogisticRegression()\n",
    "\n",
    "# within the params dictionaries, the keys should be\n",
    "# the parameter names of the algos, as per their \n",
    "# documentation\n",
    "\n",
    "# within the hp in each dictionary, give different names to\n",
    "# later on identify to which model was the hyperparameter assigned\n",
    "# see for example n_estimators_rf and n_estimators_gbm later\n",
    "\n",
    "\n",
    "# the nested space\n",
    "param_grid = hp.choice('classifier', [\n",
    "    \n",
    "    # algo 1\n",
    "    {'model': LogisticRegression,\n",
    "    'params': {\n",
    "        'penalty': hp.choice('penalty', ['l1','l2']),\n",
    "        'C' : hp.uniform('C', 0.001, 10),\n",
    "        'solver': 'saga', # the only solver that works with both penalties\n",
    "    }},\n",
    "    \n",
    "    # algo 2\n",
    "    {'model': RandomForestClassifier,\n",
    "    'params': {\n",
    "        'n_estimators': hp.quniform('n_estimators_rf', 50, 1500, 50),\n",
    "        'max_depth': hp.quniform('max_depth_rf', 1, 5, 1),\n",
    "        'criterion': hp.choice('criterion_rf', ['gini', 'entropy']),\n",
    "    }},\n",
    "    \n",
    "    # algo 3\n",
    "    {'model': GradientBoostingClassifier,\n",
    "    'params': {\n",
    "        'n_estimators': hp.quniform('n_estimators_gbm', 50, 1500, 50),\n",
    "        'max_depth': hp.quniform('max_depth_gbm', 1, 5, 1),\n",
    "        'criterion': hp.choice('criterion_gbm', ['friedman_mse', 'squared_error']),\n",
    "    }},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the objective function\n",
    "\n",
    "This is the hyperparameter response space, the function we want to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    \n",
    "    # instantiate the model\n",
    "    model = params['model']() # don't forget the () to instantiate the class\n",
    "    \n",
    "    # capture the sampled hyperparameters\n",
    "    hyperparams = params['params']\n",
    "        \n",
    "    try:        \n",
    "        # for tree based algorithms\n",
    "        hyperparams['n_estimators'] = int(hyperparams['n_estimators'])\n",
    "        hyperparams['max_depth'] = int(hyperparams['max_depth'])\n",
    "    except:\n",
    "        pass        \n",
    "        \n",
    "    # in case you want to visualize what is being sampled:\n",
    "    print(model, hyperparams)\n",
    "\n",
    "    # pass the parameters to the model\n",
    "    model.set_params(**hyperparams)\n",
    "\n",
    "    # train with cv\n",
    "    cross_val_data = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring='accuracy',\n",
    "        cv=3,\n",
    "        n_jobs=4,\n",
    "    )\n",
    "\n",
    "    # to minimize, we negate the score\n",
    "    loss = -cross_val_data.mean()\n",
    "    print(loss)\n",
    "    print()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()                                                                                                   \n",
      "{'C': 6.201569857768734, 'penalty': 'l2', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 4.430037069625402, 'penalty': 'l1', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 9.550139269380772, 'penalty': 'l2', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 6.748841211648887, 'penalty': 'l2', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 3.699500590846252, 'penalty': 'l1', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 3.0869320689216684, 'penalty': 'l2', 'solver': 'saga'}                                                           \n",
      "-0.9120148856990963                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 2, 'n_estimators': 1050}                                                   \n",
      "-0.9573175362649047                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'friedman_mse', 'max_depth': 2, 'n_estimators': 400}                                                     \n",
      "-0.9573175362649047                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 2.2226845787178777, 'penalty': 'l2', 'solver': 'saga'}                                                           \n",
      "-0.9120148856990963                                                                                                    \n",
      "RandomForestClassifier()                                                                                               \n",
      "{'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 1400}                                                         \n",
      "-0.9472544998860788                                                                                                    \n",
      "RandomForestClassifier()                                                                                               \n",
      "{'criterion': 'entropy', 'max_depth': 3, 'n_estimators': 650}                                                          \n",
      "-0.9397357028935976                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'friedman_mse', 'max_depth': 4, 'n_estimators': 550}                                                     \n",
      "-0.9372484240905293                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 6.096447534843934, 'penalty': 'l2', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 9.317658552184142, 'penalty': 'l2', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 2, 'n_estimators': 1400}                                                   \n",
      "-0.9598427887901572                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 5.564058480270031, 'penalty': 'l2', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 550}                                                    \n",
      "-0.9673236120604543                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'friedman_mse', 'max_depth': 3, 'n_estimators': 1400}                                                    \n",
      "-0.9522860180754917                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 3, 'n_estimators': 1350}                                                   \n",
      "-0.9522860180754917                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 7.789697731456888, 'penalty': 'l1', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'friedman_mse', 'max_depth': 2, 'n_estimators': 900}                                                     \n",
      "-0.9573175362649047                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 3, 'n_estimators': 600}                                                    \n",
      "-0.9522860180754917                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'friedman_mse', 'max_depth': 2, 'n_estimators': 700}                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9573175362649047                                                                                                    \n",
      "RandomForestClassifier()                                                                                               \n",
      "{'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 850}                                                          \n",
      "-0.9397357028935976                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 1050}                                                   \n",
      "-0.9723551302498671                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 3, 'n_estimators': 1200}                                                   \n",
      "-0.9547922837396522                                                                                                    \n",
      "RandomForestClassifier()                                                                                               \n",
      "{'criterion': 'entropy', 'max_depth': 4, 'n_estimators': 650}                                                          \n",
      "-0.9447482342219184                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 7.364391400734419, 'penalty': 'l2', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 1150}                                                   \n",
      "-0.9698298777246146                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 3, 'n_estimators': 900}                                                    \n",
      "-0.9547922837396522                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 950}                                                    \n",
      "-0.9698298777246146                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 7.957594003017992, 'penalty': 'l2', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 3, 'n_estimators': 1050}                                                   \n",
      "-0.9522860180754917                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 1050}                                                   \n",
      "-0.9698298777246146                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 2, 'n_estimators': 1250}                                                   \n",
      "-0.9573175362649047                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 1000}                                                   \n",
      "-0.9698298777246146                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 2, 'n_estimators': 1000}                                                   \n",
      "-0.9598427887901572                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 2, 'n_estimators': 1250}                                                   \n",
      "-0.9573175362649047                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 2, 'n_estimators': 1000}                                                   \n",
      "-0.9598238019290651                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'friedman_mse', 'max_depth': 1, 'n_estimators': 900}                                                     \n",
      "-0.9723551302498671                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 1200}                                                   \n",
      "-0.9698298777246146                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'friedman_mse', 'max_depth': 1, 'n_estimators': 750}                                                     \n",
      "-0.9723551302498671                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'friedman_mse', 'max_depth': 1, 'n_estimators': 600}                                                     \n",
      "-0.9673236120604543                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 900}                                                    \n",
      "-0.9723551302498671                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 2, 'n_estimators': 900}                                                    \n",
      "-0.9598238019290651                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'friedman_mse', 'max_depth': 2, 'n_estimators': 800}                                                     \n",
      "-0.9598238019290651                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'friedman_mse', 'max_depth': 1, 'n_estimators': 850}                                                     \n",
      "-0.9723551302498671                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 900}                                                    \n",
      "-0.9723551302498671                                                                                                    \n",
      "GradientBoostingClassifier()                                                                                           \n",
      "{'criterion': 'squared_error', 'max_depth': 1, 'n_estimators': 950}                                                    \n",
      "-0.9698298777246146                                                                                                    \n",
      "LogisticRegression()                                                                                                   \n",
      "{'C': 4.404554630288614, 'penalty': 'l1', 'solver': 'saga'}                                                            \n",
      "-0.9120148856990963                                                                                                    \n",
      "100%|███████████████████████████████████████████████| 50/50 [06:51<00:00,  8.22s/trial, best loss: -0.9723551302498671]\n"
     ]
    }
   ],
   "source": [
    "# fmin performs the minimization\n",
    "# anneal.suggest samples the parameters\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "anneal_search = fmin(\n",
    "    fn=objective,\n",
    "    space=param_grid,\n",
    "    max_evals=50,\n",
    "    rstate=np.random.default_rng(42),\n",
    "    algo=anneal.suggest,  # annealing search\n",
    "    trials=trials\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 2,\n",
       " 'criterion_gbm': 1,\n",
       " 'max_depth_gbm': 1.0,\n",
       " 'n_estimators_gbm': 1050.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anneal_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 2,\n",
       " 'criterion_gbm': 1,\n",
       " 'max_depth_gbm': 1.0,\n",
       " 'n_estimators_gbm': 1050.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9723551302498671"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.average_best_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 2,\n",
       " 'tid': 24,\n",
       " 'spec': None,\n",
       " 'result': {'loss': -0.9723551302498671, 'status': 'ok'},\n",
       " 'misc': {'tid': 24,\n",
       "  'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "  'workdir': None,\n",
       "  'idxs': {'C': [],\n",
       "   'classifier': [24],\n",
       "   'criterion_gbm': [24],\n",
       "   'criterion_rf': [],\n",
       "   'max_depth_gbm': [24],\n",
       "   'max_depth_rf': [],\n",
       "   'n_estimators_gbm': [24],\n",
       "   'n_estimators_rf': [],\n",
       "   'penalty': []},\n",
       "  'vals': {'C': [],\n",
       "   'classifier': [2],\n",
       "   'criterion_gbm': [1],\n",
       "   'criterion_rf': [],\n",
       "   'max_depth_gbm': [1.0],\n",
       "   'max_depth_rf': [],\n",
       "   'n_estimators_gbm': [1050.0],\n",
       "   'n_estimators_rf': [],\n",
       "   'penalty': []}},\n",
       " 'exp_key': None,\n",
       " 'owner': None,\n",
       " 'version': 0,\n",
       " 'book_time': datetime.datetime(2024, 9, 19, 7, 30, 19, 271000),\n",
       " 'refresh_time': datetime.datetime(2024, 9, 19, 7, 30, 29, 139000)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convergence\n",
    "\n",
    "pd.Series(trials.losses()).sort_values(ascending=False).reset_index(drop=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
